{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WWiBVBuOUm-G"
   },
   "source": [
    "# Improving Fine-tuned Model using RAG\n",
    "\n",
    "Code authored by: Shaw Talebi <br>\n",
    "Article link: https://towardsdatascience.com/how-to-improve-llms-with-rag-abdc132f76ac <br>\n",
    "Video link: https://youtu.be/Ylz779Op9Pw?si=iOvBETQDrgoK_sO6 <br>\n",
    "<br>\n",
    "Colab: https://colab.research.google.com/drive/1peJukr-9E1zCo1iAalbgDPJmNMydvQms?usp=sharing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "imVTIbGDUsRt"
   },
   "source": [
    "### imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uFwm7wDSoF3V",
    "outputId": "44bbb4bc-8a41-4d05-97cb-ea7d912c81cd"
   },
   "outputs": [],
   "source": [
    "!pip3.10 install llama-index-embeddings-huggingface\n",
    "!pip3.10 install peft\n",
    "!pip3.10 install auto-gptq\n",
    "!pip3.10 install llama-index\n",
    "!pip3.10 install optimum\n",
    "!pip3.10 install bitsandbytes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QBrjtJTQUp-u"
   },
   "outputs": [],
   "source": [
    "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
    "from llama_index.core import Settings, SimpleDirectoryReader, VectorStoreIndex\n",
    "from llama_index.core.retrievers import VectorIndexRetriever\n",
    "from llama_index.core.query_engine import RetrieverQueryEngine\n",
    "from llama_index.core.postprocessor import SimilarityPostprocessor\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gm2fzGngqRlW"
   },
   "source": [
    "### Define Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lBuIj8Xzqb6A",
    "outputId": "469d7af5-7356-4885-d897-c1d7c7090bcb"
   },
   "outputs": [],
   "source": [
    "# import any embedding model on HF hub (https://huggingface.co/spaces/mteb/leaderboard)\n",
    "Settings.embed_model = HuggingFaceEmbedding(model_name=\"BAAI/bge-small-en-v1.5\")\n",
    "# Settings.embed_model = HuggingFaceEmbedding(model_name=\"thenlper/gte-large\") # alternative model\n",
    "\n",
    "Settings.llm = None\n",
    "Settings.chunk_size = 256\n",
    "Settings.chunk_overlap = 25"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eGXecXc5tPKL"
   },
   "source": [
    "### Read and Store Docs into Vector DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_1pAvTwntWD0",
    "outputId": "d94d44f7-82ff-4afa-8560-cb2f9f534091"
   },
   "outputs": [],
   "source": [
    "# articles available here: {add GitHub repo}\n",
    "\n",
    "import os\n",
    "\n",
    "# List all files in the current directory\n",
    "print(os.listdir('./'))\n",
    "\n",
    "\n",
    "# pdf_path = \"\n",
    "# !pip install PyPDF2  # Install PyPDF2 if not already installed\n",
    "\n",
    "# from PyPDF2 import PdfReader\n",
    "\n",
    "# book_content = \"\"\n",
    "# # Open and read the PDF\n",
    "# reader = PdfReader(pdf_path)\n",
    "# for page in reader.pages:\n",
    "#     book_content += page.extract_text()\n",
    "\n",
    "# print(book_content)\n",
    "\n",
    "documents = SimpleDirectoryReader(\"data\").load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "u7mAAYYvtYLE",
    "outputId": "e2b8a98b-4846-41b7-97b0-93409e622b88"
   },
   "outputs": [],
   "source": [
    "# some ad hoc document refinement\n",
    "print(documents)\n",
    "print(len(documents))\n",
    "for doc in documents:\n",
    "    if \"Member-only story\" in doc.text:\n",
    "        documents.remove(doc)\n",
    "        continue\n",
    "\n",
    "    if \"The Data Entrepreneurs\" in doc.text:\n",
    "        documents.remove(doc)\n",
    "\n",
    "    if \" min read\" in doc.text:\n",
    "        documents.remove(doc)\n",
    "\n",
    "print(len(documents))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WqiIJUcDtce_"
   },
   "outputs": [],
   "source": [
    "# store docs into vector DB\n",
    "index = VectorStoreIndex.from_documents(documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vETeL8CZt_Bl"
   },
   "source": [
    "### Set Up Search Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jERXCirtuIKp"
   },
   "outputs": [],
   "source": [
    "# set number of docs to retreive\n",
    "top_k = 5\n",
    "\n",
    "# configure retriever\n",
    "retriever = VectorIndexRetriever(\n",
    "    index=index,\n",
    "    similarity_top_k=top_k,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Rp0PNtjHuJ39"
   },
   "outputs": [],
   "source": [
    "# assemble query engine\n",
    "query_engine = RetrieverQueryEngine(\n",
    "    retriever=retriever,\n",
    "    node_postprocessors=[SimilarityPostprocessor(similarity_cutoff=0.5)],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ciyNcoKbuS90"
   },
   "source": [
    "### Retrieve Relevant Docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VoXW6EovuO64"
   },
   "outputs": [],
   "source": [
    "# query documents\n",
    "query = \"What were the learnings of the author from When he started BrainQUICKEN LLC\"\n",
    "response = query_engine.query(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jgpoCg1Dwk_S",
    "outputId": "93a4c40a-fd8d-43ee-ff42-a9bd5002b375"
   },
   "outputs": [],
   "source": [
    "# reformat response\n",
    "context = \"Context:\\n\"\n",
    "for i in range(top_k):\n",
    "    context = context + response.source_nodes[i].text + \"\\n\\n\"\n",
    "\n",
    "print(context)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FsTh3OHpwxWV"
   },
   "source": [
    "### Import LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 478
    },
    "id": "6vlszLofwmpR",
    "outputId": "816b4ffc-b456-4e8e-8fd9-b635125e0701"
   },
   "outputs": [],
   "source": [
    "# load fine-tuned model from hub\n",
    "from peft import PeftModel, PeftConfig\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "\n",
    "model_name = \"winglian/Llama-2-3b-hf\"\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name,\n",
    "                                             device_map=\"auto\",\n",
    "                                             trust_remote_code=False,\n",
    "                                             revision=\"main\")\n",
    "\n",
    "config = PeftConfig.from_pretrained(\"shawhin/shawgpt-ft\")\n",
    "model = PeftModel.from_pretrained(model, \"shawhin/shawgpt-ft\")\n",
    "\n",
    "# load tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, use_fast=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Aajg1MVTzury"
   },
   "source": [
    "### Use LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EdtTeDQQxAHj"
   },
   "outputs": [],
   "source": [
    "# prompt (no context)\n",
    "intstructions_string = f\"\"\"I am a student that is learning from a book called the 4 hour work week\n",
    "\n",
    "Please respond to the following comment.\n",
    "\"\"\"\n",
    "prompt_template = lambda comment: f'''[INST] {intstructions_string} \\n{comment} \\n[/INST]'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pAqwqAGMz4mo",
    "outputId": "0a58f093-585e-407f-9a35-4f1c85a41e5d"
   },
   "outputs": [],
   "source": [
    "comment = \"What were the learnings of the author from When he started BrainQUICKEN LLC\"\n",
    "\n",
    "prompt = prompt_template(comment)\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "P-CFTwGa0BEB",
    "outputId": "c02ee3fe-f393-4be3-9515-2c7e3d40cb76"
   },
   "outputs": [],
   "source": [
    "model.eval()\n",
    "\n",
    "inputs = tokenizer(prompt, return_tensors=\"pt\")\n",
    "outputs = model.generate(input_ids=inputs[\"input_ids\"].to(\"cuda\"), max_new_tokens=280)\n",
    "\n",
    "print(tokenizer.batch_decode(outputs)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xjHEV6FD0I_J"
   },
   "outputs": [],
   "source": [
    "# prompt (with context)\n",
    "prompt_template_w_context = lambda context, comment: f\"\"\"[INST]I am a student that is learning from a book called the 4 hour work week\n",
    "\n",
    "{context}\n",
    "Please respond to the following comment. Use the context above if it is helpful.\n",
    "\n",
    "{comment}\n",
    "[/INST]\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gAuGtKt81TJo",
    "outputId": "7cd74608-e5fa-42ea-9c80-e75b4b744bc6"
   },
   "outputs": [],
   "source": [
    "prompt = prompt_template_w_context(context, query)\n",
    "\n",
    "inputs = tokenizer(prompt, return_tensors=\"pt\")\n",
    "outputs = model.generate(input_ids=inputs[\"input_ids\"].to(\"cuda\"), max_new_tokens=280)\n",
    "\n",
    "print(tokenizer.batch_decode(outputs)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cRUswNvJfqFk"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
